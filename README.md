# Image Captioning using attention models

### Update: 26th July 2020
Blog published at Weights and Biases: https://app.wandb.ai/authors/image-captioning/reports/Generate-Meaningful-Captions-for-Images-with-Attention-Models--VmlldzoxNzg0ODA

Code for Image Captioning now available in TF 2.0 : tensorflow-image-captioning.ipynb


## Presented at Data Hack Summit 2019 and 3rd Kaggle Days Meetup Bangalore - Senior Track 
![Alt text](image_captioning_session.png?raw=true)
![Kaggle Meetup](image_captioning_session_kaggleblr.png?raw=true)


### Task
![TASK](notebook_images/task.png?raw=true)


### Traing Data
![TASK](notebook_images/training_data.png?raw=true)

### Attention weight calculation
![ATTENTION_WEIGHTS](notebook_images/attention_dim.png?raw=true)

### Context Vector
![ATTENTION_WEIGHTS](notebook_images/context_vector.png?raw=true)

### Repository referred for coding:
https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning
Modifications done: using shared weights when calculating attention weights.
